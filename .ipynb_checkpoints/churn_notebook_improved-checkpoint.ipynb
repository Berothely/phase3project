{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9de3a7",
   "metadata": {},
   "source": [
    "\n",
    "# Churn Modeling — Imbalanced Data, Leakage-Safe, Production-Ready\n",
    "\n",
    "**What this notebook does (best-practice pipeline):**\n",
    "- Cleanly loads data and reports class imbalance.\n",
    "- Leakage-safe **Pipeline** with `SMOTENC` (resampling **inside** CV), `ColumnTransformer`, and a class-weighted **Logistic Regression**.\n",
    "- Tunes the **decision threshold** on cross-validated predictions to maximize **F1** (swap metric if needed).\n",
    "- Evaluates with **PR-AUC**, **ROC-AUC**, confusion matrix, precision, recall, F1 on a held-out test set.\n",
    "- Optional feature importance view (from the linear model coefficients).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "FILE_PATH = 'churnintelecom.csv'  # update path if needed\n",
    "TARGET = 'churn'                  # binary target: 1 = churn, 0 = no churn\n",
    "CAT_COLS = ['international plan', 'voice mail plan']  # categorical flags present in dataset\n",
    "DROP_COLS = ['phone number', 'state']                 # columns to drop (IDs / high-cardinality)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "N_SPLITS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e14db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             precision_recall_curve, average_precision_score,\n",
    "                             roc_auc_score, f1_score, precision_score, recall_score)\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ec943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ LOAD DATA ------------------\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nFirst rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nInfo:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ CLASS BALANCE ------------------\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(f\"TARGET '{TARGET}' not found in columns: {df.columns.tolist()}\")\n",
    "\n",
    "y_raw = df[TARGET]\n",
    "print(\"\\nTarget value counts:\")\n",
    "print(y_raw.value_counts())\n",
    "print(\"\\nTarget distribution (%):\")\n",
    "print((y_raw.value_counts(normalize=True) * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ CLEAN & SPLIT ------------------\n",
    "df2 = df.drop(columns=DROP_COLS, errors='ignore').copy()\n",
    "df2[TARGET] = df2[TARGET].astype(int)\n",
    "\n",
    "X = df2.drop(columns=[TARGET])\n",
    "y = df2[TARGET].values\n",
    "\n",
    "# Identify columns by dtype\n",
    "num_cols = X.select_dtypes(include=np.number).columns.difference(CAT_COLS).tolist()\n",
    "cat_cols = [c for c in CAT_COLS if c in X.columns]\n",
    "\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "\n",
    "# Train/test split (stratified)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"\\nTrain shape:\", Xtr.shape, \" Test shape:\", Xte.shape)\n",
    "print(\"Train class balance:\", np.bincount(ytr))\n",
    "print(\"Test  class balance:\", np.bincount(yte))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aaca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ PIPELINE ------------------\n",
    "# Column indices for SMOTENC (based on raw X columns)\n",
    "cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=None, sparse_output=False), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    "    C=1.0,\n",
    "    max_iter=2000\n",
    ")\n",
    "\n",
    "pipe = ImbPipeline(steps=[\n",
    "    (\"smote\", SMOTENC(categorical_features=cat_idx, random_state=RANDOM_STATE, k_neighbors=5)),\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", clf),\n",
    "])\n",
    "\n",
    "pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fab572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ CV THRESHOLD TUNING ------------------\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "proba_cv = cross_val_predict(pipe, Xtr, ytr, cv=cv, method=\"predict_proba\")[:, 1]\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(ytr, proba_cv)\n",
    "f1s = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "best_idx = np.nanargmax(f1s)\n",
    "best_thr = thr[max(best_idx, 0)] if best_idx < len(thr) else 0.5\n",
    "\n",
    "print(f\"Chosen threshold (F1-optimal on CV): {best_thr:.3f}\")\n",
    "print(\"PR-AUC (train CV):\", average_precision_score(ytr, proba_cv))\n",
    "print(\"ROC-AUC (train CV):\", roc_auc_score(ytr, proba_cv))\n",
    "\n",
    "# Optional: plot PR curve (train CV)\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Train CV)\"); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ FINAL FIT & TEST EVAL ------------------\n",
    "pipe.fit(Xtr, ytr)\n",
    "proba_te = pipe.predict_proba(Xte)[:, 1]\n",
    "pred_te = (proba_te >= best_thr).astype(int)\n",
    "\n",
    "print(\"PR-AUC (test):\", average_precision_score(yte, proba_te))\n",
    "print(\"ROC-AUC (test):\", roc_auc_score(yte, proba_te))\n",
    "print(\"F1 (test):\", f1_score(yte, pred_te))\n",
    "print(\"Precision (test):\", precision_score(yte, pred_te))\n",
    "print(\"Recall (test):\", recall_score(yte, pred_te))\n",
    "\n",
    "print(\"\\nConfusion Matrix (test):\\n\", confusion_matrix(yte, pred_te))\n",
    "print(\"\\nClassification Report (test):\\n\", classification_report(yte, pred_te, digits=3))\n",
    "\n",
    "# PR curve (test)\n",
    "prec_te, rec_te, _ = precision_recall_curve(yte, proba_te)\n",
    "plt.figure()\n",
    "plt.plot(rec_te, prec_te)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Test)\"); plt.grid(True); plt.show()\n",
    "\n",
    "# ROC curve (test)\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, _ = roc_curve(yte, proba_te)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (Test)\"); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ COEFFICIENTS / FEATURE IMPORTANCE (LOGREG) ------------------\n",
    "# Refit on full training to extract coefficients along the transformed feature names\n",
    "pipe.fit(Xtr, ytr)\n",
    "\n",
    "# Build transformed feature names\n",
    "ohe = pipe.named_steps['prep'].named_transformers_['cat']\n",
    "num_names = num_cols\n",
    "cat_names = []\n",
    "if ohe is not None and len(cat_cols) > 0:\n",
    "    cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "\n",
    "feat_names = num_names + cat_names\n",
    "\n",
    "coef = pipe.named_steps['clf'].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coefficient\": coef}).sort_values(\"coefficient\")\n",
    "\n",
    "print(coef_df.head())\n",
    "print(coef_df.tail())\n",
    "\n",
    "# Horizontal bar plot\n",
    "coef_df_plot = coef_df.copy()\n",
    "coef_df_plot = coef_df_plot.set_index(\"feature\")\n",
    "coef_df_plot.plot.barh(y=\"coefficient\")\n",
    "plt.title(\"LogReg Coefficients\")\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef26bf",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) Use a Different Threshold Objective\n",
    "If your business goal is **high recall** (catch most churners) with a minimum precision, you can pick the threshold that **maximizes recall given Precision ≥ X**. Replace the tuning cell with logic that searches thresholds under that constraint.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
